{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85fb1a01",
   "metadata": {},
   "source": [
    "Functions for image loading and showing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a85f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tifff\n",
    "\n",
    "def load_acrobat_image(datafolder, case, stain, pyr_idx, train_val_str):\n",
    "    if train_val_str.lower() == 'train':\n",
    "        image_path = datafolder + os.path.sep + str(case) + '_' + stain + '.tiff'\n",
    "    elif train_val_str.lower() == 'val':\n",
    "        image_path = datafolder + os.path.sep + str(case) + '_' + stain + '_val.tiff'\n",
    "    elif train_val_str.lower() == 'test':\n",
    "        image_path = datafolder + os.path.sep + str(case) + '_' + stain + '_test.tiff'\n",
    "    else: \n",
    "        ValueError(\"Three options for the last input: 'train' 'val' 'test'\")\n",
    "    image = tifff.imread(image_path, key=pyr_idx)\n",
    "    return(image)\n",
    "\n",
    "def show_aligned_images(moved_image_channel, target_image_channel,alpha=0.8):\n",
    "    target_image_rgb = np.transpose(np.stack((target_image_channel,target_image_channel,target_image_channel)),axes=[1,2,0])\n",
    "    target_image_rgb = target_image_rgb.astype(np.uint8)\n",
    "    aligned_images_rgb = target_image_rgb\n",
    "    aligned_images_rgb[:,:,1] = alpha*moved_image_channel + (1-alpha)*aligned_images_rgb[:,:,1]\n",
    "    aligned_images_rgb = aligned_images_rgb.astype(np.uint8)\n",
    "    return(aligned_images_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d6591",
   "metadata": {},
   "source": [
    "Functions for image preprocessing, tissue segmentation and SIFT extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90d4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def round_up_to_odd(f):\n",
    "    return np.ceil(f) // 2 * 2 + 1\n",
    "\n",
    "def segment_he_tissue(he_channel, res, sigma=25, crop_ratio=0.1):\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.2, tileGridSize=(round(100/res), round(100/res)))\n",
    "    eq = clahe.apply(he_channel)\n",
    "    \n",
    "    ksize = sigma*4\n",
    "    ksize = round_up_to_odd(ksize/res)\n",
    "    sigma = ksize/4\n",
    "    gf = cv2.GaussianBlur(eq,(int(ksize),int(ksize)),sigma)\n",
    "    \n",
    "    start_row = int(crop_ratio*gf.shape[0])\n",
    "    end_row = int(gf.shape[0]-crop_ratio*gf.shape[0])+1\n",
    "    start_col = int(crop_ratio*gf.shape[1])\n",
    "    end_col = int(gf.shape[1]-crop_ratio*gf.shape[1])+1\n",
    "    gf_crop = gf[start_row:end_row, start_col:end_col]\n",
    "        \n",
    "    pixel_vals = gf_crop.reshape((-1,1)) \n",
    "    pixel_vals = np.float32(pixel_vals)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85) #criteria\n",
    "\n",
    "    k = 3 # Choosing number of cluster\n",
    "    _, labels, centers = cv2.kmeans(pixel_vals, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) \n",
    "    \n",
    "    bg_label = labels == np.where(np.sum(centers,axis=1) == np.amin(np.sum(centers,axis=1)))\n",
    "    bg_mask = bg_label.reshape((gf_crop.shape[0:2])) # reshape data into the original image dimensions\n",
    "    bg_mask_full = cv2.copyMakeBorder(np.uint8(bg_mask), start_row, gf.shape[0] - gf_crop.shape[0] - start_row, start_col, gf.shape[1] - gf_crop.shape[1] - start_col, cv2.BORDER_CONSTANT, None, value = 1)\n",
    "    \n",
    "    tissue_mask_full = bg_mask_full == 0\n",
    "\n",
    "    return(tissue_mask_full)\n",
    "\n",
    "def segment_ihc_tissue(ihc_channel, res, sigma=25, crop_ratio=0.1):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(round(100/res), round(100/res)))\n",
    "    eq = clahe.apply(ihc_channel)\n",
    "    \n",
    "    ksize = sigma*4\n",
    "    ksize = round_up_to_odd(ksize/res)\n",
    "    sigma = ksize/4\n",
    "    gf = 255-cv2.GaussianBlur(eq,(int(ksize),int(ksize)),sigma)\n",
    "    \n",
    "    start_row = int(crop_ratio*gf.shape[0])\n",
    "    end_row = int(gf.shape[0]-crop_ratio*gf.shape[0])+1\n",
    "    start_col = int(crop_ratio*gf.shape[1])\n",
    "    end_col = int(gf.shape[1]-crop_ratio*gf.shape[1])+1\n",
    "    gf_crop = gf[start_row:end_row, start_col:end_col]\n",
    "        \n",
    "    pixel_vals = gf_crop.reshape((-1,1)) \n",
    "    pixel_vals = np.float32(pixel_vals)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85) #criteria\n",
    "    \n",
    "    k = 3 \n",
    "    _, labels, centers = cv2.kmeans(pixel_vals, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS) \n",
    "    \n",
    "    bg_label = labels == np.where(np.sum(centers,axis=1) == np.amin(np.sum(centers,axis=1)))\n",
    "    bg_mask = bg_label.reshape((gf_crop.shape[0:2])) # reshape data into the original image dimensions\n",
    "    bg_mask_full = cv2.copyMakeBorder(np.uint8(bg_mask), start_row, gf.shape[0] - gf_crop.shape[0] - start_row, start_col, gf.shape[1] - gf_crop.shape[1] - start_col, cv2.BORDER_CONSTANT, None, value = 1)\n",
    "    \n",
    "    tissue_mask_full = bg_mask_full == 0\n",
    "    \n",
    "    return(tissue_mask_full)\n",
    "\n",
    "def sift_he(he_lab, res, sigma=10, crop_ratio=0.06):\n",
    "    he_channel_seg = he_lab[:,:,1].copy()\n",
    "    he_tissue_mask = segment_he_tissue(he_channel_seg, res, sigma=25, crop_ratio=0.06)\n",
    "    \n",
    "    he_channel_sift = he_lab[:,:,0].copy()\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=0.2, tileGridSize=(round(100/res), round(100/res)))\n",
    "    he_channel_sift_eq = clahe.apply(he_channel_sift)\n",
    "    \n",
    "    sigma = 5\n",
    "    ksize = sigma*4\n",
    "    ksize = round_up_to_odd(ksize/res)\n",
    "    sigma = ksize/4\n",
    "    he_channel_sift_gf = 255-cv2.GaussianBlur(he_channel_sift_eq,(int(ksize),int(ksize)),sigma)\n",
    "    \n",
    "    start_row = int(crop_ratio*he_channel_sift_gf.shape[0])\n",
    "    end_row = int(he_channel_sift_gf.shape[0]-crop_ratio*he_channel_sift_gf.shape[0])+1\n",
    "    start_col = int(crop_ratio*he_channel_sift_gf.shape[1])\n",
    "    end_col = int(he_channel_sift_gf.shape[1]-crop_ratio*he_channel_sift_gf.shape[1])+1\n",
    "    he_channel_sift_gf[0:start_row, :] = np.median(he_channel_sift_gf[he_tissue_mask==0])\n",
    "    he_channel_sift_gf[end_row:, :] = np.median(he_channel_sift_gf[he_tissue_mask==0])\n",
    "    he_channel_sift_gf[:, 0:start_col] = np.median(he_channel_sift_gf[he_tissue_mask==0])\n",
    "    he_channel_sift_gf[:, end_col:] = np.median(he_channel_sift_gf[he_tissue_mask==0])\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    he_kp, he_des = sift.detectAndCompute(he_channel_sift_gf,None)\n",
    "    \n",
    "    he_show_keypoints = cv2.drawKeypoints(he_channel_sift_gf,he_kp,np.array([]))\n",
    "    return(he_show_keypoints,he_kp,he_des,he_tissue_mask,he_channel_sift_gf)\n",
    "\n",
    "def sift_ihc(ihc_hsv, res, sigma=10, crop_ratio=0.06):\n",
    "    ihc_channel_seg = ihc_hsv[:,:,2].copy()\n",
    "    ihc_tissue_mask = segment_ihc_tissue(ihc_channel_seg, res, sigma=25, crop_ratio=0.06)\n",
    "    \n",
    "    ihc_channel_sift = ihc_hsv[:,:,2].copy()\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(round(100/res), round(100/res)))\n",
    "    ihc_channel_sift_eq = clahe.apply(ihc_channel_sift)\n",
    "    \n",
    "    sigma = 5\n",
    "    ksize = sigma*4\n",
    "    ksize = round_up_to_odd(ksize/res)\n",
    "    sigma = ksize/4\n",
    "    ihc_channel_sift_gf = 255-cv2.GaussianBlur(ihc_channel_sift_eq,(int(ksize),int(ksize)),sigma)\n",
    "    \n",
    "    start_row = int(crop_ratio*ihc_channel_sift_gf.shape[0])\n",
    "    end_row = int(ihc_channel_sift_gf.shape[0]-crop_ratio*ihc_channel_sift_gf.shape[0])+1\n",
    "    start_col = int(crop_ratio*ihc_channel_sift_gf.shape[1])\n",
    "    end_col = int(ihc_channel_sift_gf.shape[1]-crop_ratio*ihc_channel_sift_gf.shape[1])+1\n",
    "    ihc_channel_sift_gf[0:start_row, :] = np.median(ihc_channel_sift_gf[ihc_tissue_mask==0])\n",
    "    ihc_channel_sift_gf[end_row:, :] = np.median(ihc_channel_sift_gf[ihc_tissue_mask==0])\n",
    "    ihc_channel_sift_gf[:, 0:start_col] = np.median(ihc_channel_sift_gf[ihc_tissue_mask==0])\n",
    "    ihc_channel_sift_gf[:, end_col:] = np.median(ihc_channel_sift_gf[ihc_tissue_mask==0])\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    ihc_kp,ihc_des = sift.detectAndCompute(ihc_channel_sift_gf,None)\n",
    "    \n",
    "    ihc_show_keypoints = cv2.drawKeypoints(ihc_channel_sift_gf,ihc_kp,np.array([]))\n",
    "    return(ihc_show_keypoints,ihc_kp,ihc_des,ihc_tissue_mask,ihc_channel_sift_gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f70dec",
   "metadata": {},
   "source": [
    "Matching keypoints and ransac with DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b7647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def dice(pred, true, k = 1):\n",
    "    intersection = np.sum(pred[true==k]) * 2.0\n",
    "    dice = intersection / (np.sum(pred) + np.sum(true))\n",
    "    return dice\n",
    "\n",
    "def umeyama(P, Q):\n",
    "    assert P.shape == Q.shape\n",
    "    n, dim = P.shape\n",
    "\n",
    "    centeredP = P - P.mean(axis=0)\n",
    "    centeredQ = Q - Q.mean(axis=0)\n",
    "\n",
    "    C = np.dot(np.transpose(centeredP), centeredQ) / n\n",
    "\n",
    "    V, S, W = np.linalg.svd(C)\n",
    "    d = (np.linalg.det(V) * np.linalg.det(W)) < 0.0\n",
    "\n",
    "    if d:\n",
    "        S[-1] = -S[-1]\n",
    "        V[:, -1] = -V[:, -1]\n",
    "\n",
    "    R = np.dot(V, W)\n",
    "\n",
    "    varP = np.var(P, axis=0).sum()\n",
    "    c = 1/varP * np.sum(S) # scale factor\n",
    "\n",
    "    t = Q.mean(axis=0) - P.mean(axis=0).dot(c*R)\n",
    "\n",
    "    return c, R, t\n",
    "\n",
    "def matching_keypoints(source_image,target_image,source_des,target_des,source_kp,target_kp,lowe_ratio=0.9):\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(source_des,target_des,k=2)\n",
    "    \n",
    "    # Lowe's Ratio test\n",
    "    good = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < lowe_ratio*n.distance:\n",
    "            good.append(m)\n",
    "    \n",
    "    good_source_kp = np.float32([ source_kp[m.queryIdx].pt for m in good ]).reshape(-1, 2)\n",
    "    good_target_kp = np.float32([ target_kp[m.trainIdx].pt for m in good ]).reshape(-1, 2)\n",
    "        \n",
    "    n_good = len(good)\n",
    "    good_source_kp_cv2 = [cv2.KeyPoint(point[0], point[1], 1) for point in good_source_kp]\n",
    "    good_target_kp_cv2 = [cv2.KeyPoint(point[0], point[1], 1) for point in good_target_kp]\n",
    "    placeholder_matches = [cv2.DMatch(idx, idx, 1) for idx in range(n_good)]\n",
    "    show_matching_keypoints = cv2.drawMatches(source_image, good_source_kp_cv2, target_image, good_target_kp_cv2, placeholder_matches, None)\n",
    "    return(good_source_kp, good_target_kp,show_matching_keypoints)\n",
    "\n",
    "def dransac(source_kp, target_kp, source_tissue_mask, target_tissue_mask, proc_source_image, proc_target_image, source_image, target_image, epochs=30000, err_threshold=50, dice_weight=0.5, ninliers_weight=0.5):\n",
    "    cols = target_tissue_mask.shape[1]\n",
    "    rows = target_tissue_mask.shape[0]\n",
    "    \n",
    "    tot_indices = []\n",
    "    tot_dice = []\n",
    "    tot_mi = []\n",
    "    tot_ninliers = []\n",
    "    \n",
    "    nsamples_iter = 3\n",
    "    for itera in tqdm.tqdm(range(epochs)):\n",
    "        indices = np.random.permutation(len(source_kp))[0:nsamples_iter]\n",
    "        curr_source_kp = source_kp[indices,:]\n",
    "        curr_target_kp = target_kp[indices,:]\n",
    "    \n",
    "        c, R, t = umeyama(curr_source_kp, curr_target_kp)\n",
    "\n",
    "        if c > 0.95 and c < 1.05:\n",
    "            tot_indices.append(indices)\n",
    "            alpha = c*R[0,0]\n",
    "            beta = c*R[0,1]\n",
    "            M = np.float32([[alpha, -beta, t[0]],[beta, alpha, t[1]]])\n",
    "            source_tissue_mask_reg = cv2.warpAffine(np.float32(source_tissue_mask), M, (cols,rows))\n",
    "            source_kp_reg = source_kp.dot(c * R) + t\n",
    "\n",
    "            err = np.sqrt(np.sum((source_kp_reg - target_kp) ** 2,axis=1))\n",
    "            idx_inlier = np.where(err<err_threshold)\n",
    "            n_inlier = len(idx_inlier[0])\n",
    "            tot_ninliers.append(n_inlier)        \n",
    "\n",
    "            curr_dice = dice(source_tissue_mask_reg,target_tissue_mask)\n",
    "            tot_dice.append(curr_dice) \n",
    "\n",
    "    tot_ninliers = np.array(tot_ninliers)\n",
    "    tot_ninliers_n = (tot_ninliers - tot_ninliers.min()) / (tot_ninliers.max() - tot_ninliers.min())\n",
    "    \n",
    "    tot_dice = np.array(tot_dice)\n",
    "    tot_dice_n = (tot_dice - tot_dice.min()) / (tot_dice.max() - tot_dice.min())\n",
    "    \n",
    "    obj_func = dice_weight*tot_dice_n**2 + ninliers_weight*tot_ninliers_n**2\n",
    "\n",
    "    best_iter = np.argmax(obj_func)\n",
    "    best_ninliers = tot_ninliers[best_iter]\n",
    "    best_dice = tot_dice[best_iter]\n",
    "    \n",
    "    print('Best iteration: ' + str(best_iter) +\n",
    "    ' Number of inliers: ' + str(best_ninliers) +\n",
    "    ' Dice: ' + str(best_dice))  \n",
    "\n",
    "    best_source_kp = source_kp[tot_indices[best_iter],:]\n",
    "    best_target_kp = target_kp[tot_indices[best_iter],:]\n",
    "    \n",
    "    c, R, t = umeyama(best_source_kp, best_target_kp)\n",
    "    source_kp_reg = source_kp.dot(c * R) + t\n",
    "    err = np.sqrt(np.sum((source_kp_reg - target_kp) ** 2,axis=1))\n",
    "    idx_best_inlier = np.where(err<err_threshold)\n",
    "    best_n_inlier = len(idx_best_inlier[0])\n",
    "    best_inlier_source_kp = source_kp[idx_best_inlier]\n",
    "    best_inlier_target_kp = target_kp[idx_best_inlier]\n",
    "    c, R, t = umeyama(best_inlier_source_kp, best_inlier_target_kp)\n",
    "    alpha = c*R[0,0]\n",
    "    beta = c*R[0,1]\n",
    "    best_M = np.float32([[alpha, -beta, t[0]],[beta, alpha, t[1]]])\n",
    "\n",
    "    best_inlier_source_kp_cv2 = [cv2.KeyPoint(point[0], point[1], 1) for point in best_inlier_source_kp]\n",
    "    best_inlier_target_kp_cv2 = [cv2.KeyPoint(point[0], point[1], 1) for point in best_inlier_target_kp]\n",
    "    placeholder_matches = [cv2.DMatch(idx, idx, 1) for idx in range(best_n_inlier)]\n",
    "    show_best_matching_keypoints = cv2.drawMatches(source_image, best_inlier_source_kp_cv2, target_image, best_inlier_target_kp_cv2, placeholder_matches, None)\n",
    "    return(best_M,best_ninliers,best_dice,show_best_matching_keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec3085",
   "metadata": {},
   "source": [
    "INR models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff9eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"This is a dense neural network with sine activation functions.\n",
    "\n",
    "    Arguments:\n",
    "    layers -- ([*int]) amount of nodes in each layer of the network, e.g. [2, 16, 16, 1]\n",
    "    gpu -- (boolean) use GPU when True, CPU when False\n",
    "    weight_init -- (boolean) use special weight initialization if True\n",
    "    omega -- (float) parameter used in the forward function\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layers, gpu=False, weight_init=True, omega=30):\n",
    "        \"\"\"Initialize the network.\"\"\"\n",
    "\n",
    "        super(Siren, self).__init__()\n",
    "        \n",
    "        self.n_layers = len(layers) - 1\n",
    "        self.omega = omega\n",
    "\n",
    "        # Make the layers\n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "\n",
    "            # Weight Initialization\n",
    "            if weight_init:\n",
    "                with torch.no_grad():\n",
    "                    if i == 0:\n",
    "                        self.layers[-1].weight.uniform_(-1 / layers[i],\n",
    "                                                        1 / layers[i])\n",
    "                    else:\n",
    "                        self.layers[-1].weight.uniform_(-np.sqrt(6 / layers[i]) / self.omega,\n",
    "                                                        np.sqrt(6 / layers[i]) / self.omega)\n",
    "\n",
    "        # Combine all layers to one model\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function of the network.\"\"\"\n",
    "        # Perform relu on all layers except for the last one\n",
    "        for layer in self.layers[:-1]:\n",
    "            z = layer(x)            \n",
    "            x = torch.sin(self.omega * z)\n",
    "\n",
    "        # Propagate through final layer and return the output\n",
    "        x = self.layers[-1](x)    \n",
    "        return x \n",
    "    \n",
    "    \n",
    "class BaseNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        \"\"\"Initialize the network.\"\"\"\n",
    "\n",
    "        super(BaseNet, self).__init__()        \n",
    "        \n",
    "        self.n_layers = len(layers) - 1\n",
    "\n",
    "        # Make the layers\n",
    "        self.layers = []\n",
    "        for i in range(self.n_layers):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            \n",
    "        # Combine all layers to one model\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward function of the network.\"\"\"\n",
    "        # Perform relu on all layers except for the last one\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.nn.functional.relu(layer(x))\n",
    "\n",
    "        # Propagate through final layer and return the output\n",
    "        return self.layers[-1](x)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f1a968",
   "metadata": {},
   "source": [
    "NCC Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de0a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "class StableStd(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor):\n",
    "        assert tensor.numel() > 1\n",
    "        ctx.tensor = tensor.detach()\n",
    "        res = torch.std(tensor).detach()\n",
    "        ctx.result = res.detach()\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        tensor = ctx.tensor.detach()\n",
    "        result = ctx.result.detach()\n",
    "        e = 1e-6\n",
    "        assert tensor.numel() > 1\n",
    "        return (\n",
    "            (2.0 / (tensor.numel() - 1.0))\n",
    "            * (grad_output.detach() / (result.detach() * 2 + e))\n",
    "            * (tensor.detach() - tensor.mean().detach())\n",
    "        )\n",
    "\n",
    "\n",
    "stablestd = StableStd.apply\n",
    "\n",
    "def ncc(x1, x2, e=1e-10):\n",
    "    assert x1.shape == x2.shape, \"Inputs are not of similar shape\"\n",
    "    x1 = x1.view(-1, 25)\n",
    "    x2 = x2.view(-1, 25)\n",
    "    cc = ((x1 - x1.mean(dim=1)[:, None]) * (x2 - x2.mean(dim=1)[:, None])).mean(dim=1)\n",
    "    std = x1.std(dim=1) * x2.std(dim=1)\n",
    "    ncc = torch.mean(cc/(std+e))\n",
    "    return ncc\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class NCC(_Loss):\n",
    "    def __init__(self, use_mask: bool = False):\n",
    "        super().__init__()\n",
    "        self.forward = self.metric\n",
    "\n",
    "    def metric(self, fixed: Tensor, warped: Tensor) -> Tensor:\n",
    "        return -ncc(fixed, warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938b7a9",
   "metadata": {},
   "source": [
    "Functions for the learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34491e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningModel():\n",
    "    \"\"\"This class contains functions which are useful for all the learning models.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize the learning model.\"\"\"\n",
    "\n",
    "        # Set all default arguments in a dict: self.args\n",
    "        self.setDefaultArguments()\n",
    "\n",
    "        # Check if all kwargs keys are valid (this checks for typos)\n",
    "        assert all(kwarg in self.args.keys() for kwarg in kwargs)\n",
    "\n",
    "        # Parse important argument from kwargs\n",
    "        self.epochs = kwargs['epochs'] if 'epochs' in kwargs else self.args['epochs']\n",
    "        self.log_interval = kwargs['log_interval'] if 'log_interval' in kwargs else self.args['log_interval']\n",
    "        self.gpu = kwargs['gpu'] if 'gpu' in kwargs else self.args['gpu']\n",
    "        self.lr = kwargs['lr'] if 'lr' in kwargs else self.args['lr']\n",
    "        self.momentum = kwargs['momentum'] if 'momentum' in kwargs else self.args['momentum']\n",
    "        self.optimizer_arg = kwargs['optimizer'] if 'optimizer' in kwargs else self.args['optimizer']\n",
    "        self.loss_function_arg = kwargs['loss_function'] if 'loss_function' in kwargs else self.args['loss_function']\n",
    "        self.layers = kwargs['layers'] if 'layers' in kwargs else self.args['layers']\n",
    "        self.weight_init = kwargs['weight_init'] if 'weight_init' in kwargs else self.args['weight_init']\n",
    "        self.omega = kwargs['omega'] if 'omega' in kwargs else self.args['omega']\n",
    "        self.save_folder = kwargs['save_folder'] if 'save_folder' in kwargs else self.args['save_folder']\n",
    "        self.gabor_scale = kwargs['gabor_scale'] if 'gabor_scale' in kwargs else self.args['gabor_scale']\n",
    "\n",
    "        # Parse other arguments from kwargs\n",
    "        self.verbose = kwargs['verbose'] if 'verbose' in kwargs else self.args['verbose']\n",
    "\n",
    "        # Make folder for output\n",
    "        if not self.save_folder == '' and not os.path.isdir(self.save_folder):\n",
    "            os.mkdir(self.save_folder)\n",
    "\n",
    "        # Add slash to divide folder and filename\n",
    "        self.save_folder += '/'\n",
    "\n",
    "        # Make loss list to save losses\n",
    "        self.loss_list = [0 for _ in range(self.epochs)]\n",
    "        self.data_loss_list = [0 for _ in range(self.epochs)]\n",
    "\n",
    "        # Set seed\n",
    "        torch.manual_seed(self.args['seed'])\n",
    "\n",
    "        # Load network\n",
    "        self.network_from_file = kwargs['network'] if 'network' in kwargs else self.args['network']\n",
    "        if self.network_from_file is None:\n",
    "            self.network = BaseNet(self.layers) \n",
    "            # self.network = Siren(self.layers, self.gpu, self.weight_init, self.omega)            \n",
    "        else:\n",
    "            self.network = torch.load(self.network_from_file)\n",
    "            if self.gpu:\n",
    "                self.network.cuda()\n",
    "\n",
    "        # Choose the optimizer\n",
    "        if self.optimizer_arg.lower() == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.network.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "\n",
    "        elif self.optimizer_arg.lower() == 'adam':\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.lr) # Adam(self.network.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer_arg.lower() == 'adadelta':\n",
    "            self.optimizer = optim.Adadelta(self.network.parameters(), lr=self.lr)\n",
    "\n",
    "        elif self.optimizer_arg.lower() == 'rmsprop':\n",
    "            self.optimizer = optim.RMSprop(self.network.parameters(), lr=self.lr)            \n",
    "            \n",
    "        else:\n",
    "            self.optimizer = optim.SGD(self.network.parameters(), lr=self.lr, momentum=self.momentum)\n",
    "            print('WARNING: ' + str(self.optimizer_arg) + ' not recognized as optimizer, picked SGD instead')\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, self.epochs // 3, gamma=0.5)\n",
    "        \n",
    "        # Choose the loss function\n",
    "        if self.loss_function_arg.lower() == 'mse':\n",
    "            self.criterion = nn.MSELoss()\n",
    "\n",
    "        elif self.loss_function_arg.lower() == 'l1':\n",
    "            self.criterion = nn.L1Loss()\n",
    "\n",
    "        elif self.loss_function_arg.lower() == 'ncc':\n",
    "            self.criterion = NCC()            \n",
    "            \n",
    "        elif self.loss_function_arg.lower() == 'smoothl1':\n",
    "            self.criterion = nn.SmoothL1Loss(beta=0.2)\n",
    "            \n",
    "        elif self.loss_function_arg.lower() == 'huber':\n",
    "            self.criterion = nn.HuberLoss()            \n",
    "\n",
    "        else:\n",
    "            self.criterion = nn.MSELoss()\n",
    "            print('WARNING: ' + str(self.loss_function_arg) + ' not recognized as loss function, picked MSE instead')\n",
    "\n",
    "        # Move variables to GPU\n",
    "        if self.gpu:\n",
    "            self.network.cuda()\n",
    "\n",
    "    def cuda(self):\n",
    "        \"\"\"Move the model to the GPU.\"\"\"\n",
    "\n",
    "        self.gpu = True\n",
    "        self.network.cuda()\n",
    "        \n",
    "    def divergence(self, input_coords, output):\n",
    "        \"\"\"Compute the divergence of the output wrt the input.\"\"\"\n",
    "\n",
    "        div = 0\n",
    "        for i in range(output.shape[-1]):\n",
    "            div += torch.autograd.grad(output[..., i], input_coords, torch.ones_like(output[..., i]), create_graph=True)[0][..., i:i + 1]\n",
    "        return div\n",
    "\n",
    "    def gradient(self, input_coords, output, grad_outputs=None):\n",
    "        \"\"\"Compute the gradient of the output wrt the input.\"\"\"\n",
    "\n",
    "        grad_outputs = torch.ones_like(output)\n",
    "        grad = torch.autograd.grad(output, [input_coords], grad_outputs=grad_outputs, create_graph=True)[0]\n",
    "        return grad\n",
    "\n",
    "    def laplace(self, input_coords, output, grad_outputs=None):\n",
    "        \"\"\"Compute the laplacian of the output wrt the input.\"\"\"\n",
    "\n",
    "        grad = self.gradient(input_coords, output)\n",
    "\n",
    "        return self.divergence(input_coords, grad)\n",
    "\n",
    "    def makeCoordinateSlice(self, dims=(28, 28), dimension=0, slice_pos=0, gpu=True):\n",
    "        \"\"\"Make a coordinate tensor.\"\"\"\n",
    "\n",
    "        dims = list(dims)\n",
    "\n",
    "        coordinate_tensor = [torch.linspace(-1, 1, dims[i]) for i in range(2)]\n",
    "        coordinate_tensor = torch.meshgrid(*coordinate_tensor)\n",
    "        coordinate_tensor = torch.stack(coordinate_tensor, dim=2)\n",
    "        coordinate_tensor = coordinate_tensor.view([np.prod(dims), 2])\n",
    "\n",
    "        # Move to GPU if necessary\n",
    "        if self.gpu and gpu:\n",
    "            coordinate_tensor = coordinate_tensor.cuda()\n",
    "\n",
    "        return coordinate_tensor\n",
    "\n",
    "    def makeCoordinateTensor(self, dims=(28, 28, 28), gpu=True):\n",
    "        \"\"\"Make a coordinate tensor.\"\"\"\n",
    "\n",
    "        coordinate_tensor = [torch.linspace(-1, 1, dims[i]) for i in range(3)]\n",
    "        coordinate_tensor = torch.meshgrid(*coordinate_tensor)\n",
    "        coordinate_tensor = torch.stack(coordinate_tensor, dim=3)\n",
    "        coordinate_tensor = coordinate_tensor.view([np.prod(dims), 3])\n",
    "\n",
    "        # Move to GPU if necessary\n",
    "        if self.gpu and gpu:\n",
    "            coordinate_tensor = coordinate_tensor.cuda()\n",
    "\n",
    "        return coordinate_tensor\n",
    "    \n",
    "    def makeMaskedCoordinateTensor(self, mask, dims=(28, 28, 28), gpu=True):\n",
    "        \"\"\"Make a coordinate tensor.\"\"\"\n",
    "\n",
    "        coordinate_tensor = [torch.linspace(-1, 1, dims[i]) for i in range(2)]\n",
    "        coordinate_tensor = torch.meshgrid(*coordinate_tensor)\n",
    "        coordinate_tensor = torch.stack(coordinate_tensor, dim=2)\n",
    "        coordinate_tensor = coordinate_tensor.view([np.prod(dims), 2])\n",
    "        coordinate_tensor = coordinate_tensor[mask.flatten() > 0, :]\n",
    "\n",
    "        # Move to GPU if necessary\n",
    "        if self.gpu and gpu:\n",
    "            coordinate_tensor = coordinate_tensor.cuda()\n",
    "\n",
    "        return coordinate_tensor  \n",
    "    \n",
    "    def setDefaultArguments(self):\n",
    "        \"\"\"Set default arguments.\"\"\"\n",
    "\n",
    "        self.args = {}\n",
    "\n",
    "        self.args['network'] = None\n",
    "\n",
    "        self.args['epochs'] = 200\n",
    "        self.args['log_interval'] = 250\n",
    "        self.args['verbose'] = True\n",
    "        self.args['save_folder'] = 'output'\n",
    "\n",
    "        self.args['gpu'] = torch.cuda.is_available()\n",
    "        self.args['optimizer'] = 'Adam'\n",
    "        self.args['loss_function'] = 'MSE'\n",
    "        self.args['lr'] = 0.001\n",
    "        self.args['momentum'] = 0.5\n",
    "\n",
    "        self.args['layers'] = [2, 32, 32, 32, 1]\n",
    "        self.args['positional_encoding'] = False\n",
    "        self.args['weight_init'] = True\n",
    "        self.args['omega'] = 30\n",
    "\n",
    "        self.args['seed'] = 1 # 13 # 2 # 1\n",
    "        \n",
    "        self.args['offset'] = [0, 0, 0]\n",
    "        self.args['gabor_scale'] = 1.0\n",
    "        \n",
    "    def train(self, epochs=None, red_blue=False):\n",
    "        \"\"\"Train the network.\"\"\"\n",
    "        # Determine epochs\n",
    "        if epochs is None:\n",
    "            epochs = self.epochs\n",
    "\n",
    "        # Set seed\n",
    "        torch.manual_seed(self.args['seed'])\n",
    "\n",
    "        # Extend lost_list if necessary\n",
    "        if not len(self.loss_list) == epochs:\n",
    "            self.loss_list = [0 for _ in range(epochs)]\n",
    "            self.data_loss_list = [0 for _ in range(epochs)]\n",
    "\n",
    "        # Perform training iterations\n",
    "        for i in tqdm.tqdm(range(epochs)):\n",
    "            self.trainingIteration(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b6f06",
   "metadata": {},
   "source": [
    "Functions for registering two images using the INR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0354329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import compare_images\n",
    "      \n",
    "class ImplicitRegistrator(LearningModel):\n",
    "    \"\"\"This is a class for registrating implicitly represented images.\"\"\"\n",
    "\n",
    "    def __call__(self, coordinate_tensor=None, output_shape=(28, 28), dimension=0, slice_pos=0):\n",
    "        \"\"\"Return the image-values for the given input-coordinates.\"\"\"\n",
    "\n",
    "        output_size = np.prod(output_shape)\n",
    "\n",
    "        # Use standard coordinate tensor if none is given\n",
    "        if coordinate_tensor is None:\n",
    "            coordinate_tensor = self.makeCoordinateSlice(output_shape, dimension, slice_pos)\n",
    "\n",
    "        output = self.network(coordinate_tensor)\n",
    "\n",
    "        # Shift coordinates by 1/n * v\n",
    "        coord_temp = torch.add(output, coordinate_tensor)\n",
    "        \n",
    "        output = coord_temp\n",
    "\n",
    "        transformed_image = self.transformNoAdd(coord_temp)\n",
    "        return transformed_image.cpu().detach().numpy()\n",
    "\n",
    "    def __init__(self, moving_image, fixed_image, **kwargs):\n",
    "        \"\"\"Initialize the registrator.\"\"\"\n",
    "\n",
    "        # Initialize standard learning model\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Parse arguments from kwargs\n",
    "        self.mask = kwargs['mask'] if 'mask' in kwargs else self.args['mask']\n",
    "       \n",
    "        # Velocity integration steps\n",
    "        self.velocity_steps = kwargs['velocity_steps'] if 'velocity_steps' in kwargs else self.args['velocity_steps']\n",
    "\n",
    "        # Parse regularization kwargs\n",
    "        self.output_regularization = kwargs['output_regularization'] if 'output_regularization' in kwargs else self.args['output_regularization']\n",
    "        self.alpha_output = kwargs['alpha_output'] if 'alpha_output' in kwargs else self.args['alpha_output']\n",
    "        self.reg_norm_output = kwargs['reg_norm_output'] if 'reg_norm_output' in kwargs else self.args['reg_norm_output']\n",
    "\n",
    "        self.jacobian_regularization = kwargs['jacobian_regularization'] if 'jacobian_regularization' in kwargs else self.args['jacobian_regularization']\n",
    "        self.alpha_jacobian = kwargs['alpha_jacobian'] if 'alpha_jacobian' in kwargs else self.args['alpha_jacobian']\n",
    "        self.reg_norm_jacobian = kwargs['reg_norm_jacobian'] if 'reg_norm_jacobian' in kwargs else self.args['reg_norm_jacobian']\n",
    "\n",
    "        self.diffusion_regularization = kwargs['diffusion_regularization'] if 'diffusion_regularization' in kwargs else self.args['diffusion_regularization']\n",
    "        self.alpha_diffusion = kwargs['alpha_diffusion'] if 'alpha_diffusion' in kwargs else self.args['alpha_diffusion']\n",
    "\n",
    "        self.elastic_regularization = kwargs['elastic_regularization'] if 'elastic_regularization' in kwargs else self.args['elastic_regularization']\n",
    "        self.alpha_elastic = kwargs['alpha_elastic'] if 'alpha_elastic' in kwargs else self.args['alpha_elastic']\n",
    "\n",
    "        self.quadratic_regularization = kwargs['quadratic_regularization'] if 'quadratic_regularization' in kwargs else self.args['quadratic_regularization']\n",
    "        self.alpha_quadratic = kwargs['alpha_quadratic'] if 'alpha_quadratic' in kwargs else self.args['alpha_quadratic']\n",
    "\n",
    "        self.ogden_regularization = kwargs['ogden_regularization'] if 'ogden_regularization' in kwargs else self.args['ogden_regularization']\n",
    "        self.alpha_ogden = kwargs['alpha_ogden'] if 'alpha_ogden' in kwargs else self.args['alpha_ogden']\n",
    "\n",
    "        self.hyper_regularization = kwargs['hyper_regularization'] if 'hyper_regularization' in kwargs else self.args['hyper_regularization']\n",
    "        self.alpha_hyper = kwargs['alpha_hyper'] if 'alpha_hyper' in kwargs else self.args['alpha_hyper']\n",
    "\n",
    "        self.time_regularization = kwargs['time_regularization'] if 'time_regularization' in kwargs else self.args['time_regularization']\n",
    "        self.alpha_time = kwargs['alpha_time'] if 'alpha_time' in kwargs else self.args['alpha_time']\n",
    "\n",
    "        self.bending_regularization = kwargs['bending_regularization'] if 'bending_regularization' in kwargs else self.args['bending_regularization']\n",
    "        self.alpha_bending = kwargs['alpha_bending'] if 'alpha_bending' in kwargs else self.args['alpha_bending']        \n",
    "        \n",
    "        # Set seed\n",
    "        torch.manual_seed(self.args['seed'])\n",
    "\n",
    "        # Parse arguments from kwargs\n",
    "        self.image_shape = kwargs['image_shape'] if 'image_shape' in kwargs else self.args['image_shape']\n",
    "        self.batch_size = kwargs['batch_size'] if 'batch_size' in kwargs else self.args['batch_size']\n",
    "\n",
    "        # Initialization\n",
    "        self.moving_image = moving_image\n",
    "        self.fixed_image = fixed_image\n",
    "        \n",
    "        self.image_shape = (int(self.fixed_image.shape[0]), int(self.fixed_image.shape[1]))\n",
    "        self.possible_coordinate_tensor = self.makeMaskedCoordinateTensor(self.mask, self.fixed_image.shape)       \n",
    "        ncc_width = 0.025 #  (1-epoch/self.epochs)*0.3+0.0001        \n",
    "        coordinate_tensor_loc = [torch.linspace(-1*ncc_width, ncc_width, 5) for i in range(2)]\n",
    "        coordinate_tensor_loc = torch.meshgrid(*coordinate_tensor_loc)\n",
    "        coordinate_tensor_loc = torch.stack(coordinate_tensor_loc, dim=2)\n",
    "        coordinate_tensor_loc = coordinate_tensor_loc.view([25, 2])\n",
    "        coordinate_tensor_loc = torch.tile(coordinate_tensor_loc, (int(self.batch_size/25), 1))\n",
    "        self.coordinate_tensor_loc = coordinate_tensor_loc.cuda()    \n",
    "    \n",
    "    \n",
    "        if self.gpu:\n",
    "            self.moving_image = self.moving_image.cuda()\n",
    "            self.fixed_image = self.fixed_image.cuda()\n",
    "\n",
    "        # Make coordinate_slice and image tensor for showing progress\n",
    "        if self.verbose:\n",
    "            self.coordinate_slice = self.makeCoordinateSlice(self.image_shape, 1, 0)\n",
    "            self.fixed_image_tensor = self.interpolate(self.fixed_image, self.coordinate_slice)\n",
    "            self.fixed_image_tensor = self.fixed_image_tensor.detach().cpu().view(self.image_shape)\n",
    "            self.fixed_image_tensor_masked = self.interpolate(self.fixed_image  * torch.from_numpy(self.mask).cuda(), self.coordinate_slice)\n",
    "            self.fixed_image_tensor_masked = self.fixed_image_tensor_masked.detach().cpu().view(self.image_shape)            \n",
    "\n",
    "        # Move variables to GPU\n",
    "        if self.gpu:\n",
    "            self.moving_image.cuda()\n",
    "            self.fixed_image.cuda()\n",
    "        \n",
    "        self.offset = torch.FloatTensor(kwargs['offset']).cuda()\n",
    "\n",
    "    def computeDiffusionLoss(self, input_coords, output, batch_size=None):\n",
    "        \"\"\"Compute the diffustion regularization loss.\"\"\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        jacobian_matrix = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "\n",
    "        loss = torch.linalg.norm(jacobian_matrix, dim=2)\n",
    "        loss = torch.pow(loss, 2)\n",
    "        loss = torch.sum(loss)\n",
    "\n",
    "        return 0.5 * loss / batch_size\n",
    "\n",
    "    def computeElasticLoss(self, input_coords, output, batch_size=None, nu=1, mu=1):\n",
    "        \"\"\"Compute the (linear) elastic regularization loss.\"\"\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        jacobian_matrix = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "\n",
    "        V = jacobian_matrix + torch.transpose(jacobian_matrix, 1, 2)\n",
    "        V = 0.5 * V\n",
    "\n",
    "        loss = nu * torch.sum(torch.pow(self.computeTrace(V), 2))\n",
    "        loss += mu * self.computeTraceSum(torch.matmul(V, V))\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def computeHyperElasticLoss(self, input_coords, output, batch_size=None, alpha_l=1, alpha_a=1, alpha_v=1):\n",
    "        \"\"\"Compute the hyper-elastic regularization loss.\"\"\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        grad_u = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "        grad_y = self.computeJacobianMatrix(input_coords, output, add_identity=True)  # This is slow, faster to infer from grad_u\n",
    "\n",
    "        # Compute length loss\n",
    "        length_loss = torch.linalg.norm(grad_u, dim=(1, 2))\n",
    "        length_loss = torch.pow(length_loss, 2)\n",
    "        length_loss = torch.sum(length_loss)\n",
    "        length_loss = 0.5 * alpha_l * length_loss\n",
    "\n",
    "        # Compute cofactor matrices for the area loss\n",
    "        cofactors = torch.zeros(batch_size, 3, 3)\n",
    "\n",
    "        # Compute elements of cofactor matrices one by one (Ugliest solution ever?)\n",
    "        cofactors[:, 0, 0] = torch.det(grad_y[:, 1:, 1:])\n",
    "        cofactors[:, 0, 1] = torch.det(grad_y[:, 1:, 0::2])\n",
    "        cofactors[:, 0, 2] = torch.det(grad_y[:, 1:, :2])\n",
    "        cofactors[:, 1, 0] = torch.det(grad_y[:, 0::2, 1:])\n",
    "        cofactors[:, 1, 1] = torch.det(grad_y[:, 0::2, 0::2])\n",
    "        cofactors[:, 1, 2] = torch.det(grad_y[:, 0::2, :2])\n",
    "        cofactors[:, 2, 0] = torch.det(grad_y[:, :2, 1:])\n",
    "        cofactors[:, 2, 1] = torch.det(grad_y[:, :2, 0::2])\n",
    "        cofactors[:, 2, 2] = torch.det(grad_y[:, :2, :2])\n",
    "\n",
    "        # Compute area loss\n",
    "        area_loss = torch.pow(cofactors, 2)\n",
    "        area_loss = torch.sum(area_loss, dim=1)\n",
    "        area_loss = area_loss - 1\n",
    "        area_loss = torch.maximum(area_loss, torch.zeros_like(area_loss))\n",
    "        area_loss = torch.pow(area_loss, 2)\n",
    "        area_loss = torch.sum(area_loss)  # sum over dimension 1 and then 0\n",
    "        area_loss = alpha_a * area_loss\n",
    "\n",
    "        # Compute volume loss\n",
    "        volume_loss = torch.det(grad_y)\n",
    "        volume_loss = torch.mul(torch.pow(volume_loss - 1, 4), torch.pow(volume_loss, -2))\n",
    "        volume_loss = torch.sum(volume_loss)\n",
    "        volume_loss = alpha_v * volume_loss\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = length_loss + area_loss + volume_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def computeBendingEnergy(self, input_coords, output, batch_size=None):\n",
    "        \"\"\"Compute the bending energy.\"\"\"\n",
    "        \n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        \n",
    "        jacobian_matrix = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "\n",
    "        dx_xy = torch.zeros(input_coords.shape[0], 2, 2)\n",
    "        dy_xy = torch.zeros(input_coords.shape[0], 2, 2)\n",
    "        for i in range(2):\n",
    "            dx_xy[:, i, :] = self.gradient(input_coords, jacobian_matrix[:, i, 0])\n",
    "            dy_xy[:, i, :] = self.gradient(input_coords, jacobian_matrix[:, i, 1])\n",
    "\n",
    "        dx_xy = torch.square(dx_xy)\n",
    "        dy_xy = torch.square(dy_xy)\n",
    "\n",
    "        loss = torch.mean(dx_xy[:, :, 0]) + torch.mean(dy_xy[:, :, 1])\n",
    "        loss += 2 * torch.mean(dx_xyz[:, :, 1]) + 2 * torch.mean(dx_xyz[:, :, 2]) + torch.mean(dy_xyz[:, :, 2])\n",
    "\n",
    "        return loss / batch_size\n",
    "    \n",
    "    def computeJacobianLoss(self, input_coords, output, batch_size=None):\n",
    "        \"\"\"Compute the jacobian regularization loss.\"\"\"\n",
    "\n",
    "        # Compute Jacobian matrices\n",
    "        jac = self.computeJacobianMatrix(input_coords, output)\n",
    "\n",
    "        # Compute determinants and take norm\n",
    "        loss = torch.det(jac) - 1\n",
    "        loss = torch.linalg.norm(loss, self.reg_norm_jacobian)\n",
    "\n",
    "        return loss / self.batch_size\n",
    "\n",
    "    def computeJacobianMatrix(self, input_coords, output, add_identity=True):\n",
    "        \"\"\"Compute the Jacobian matrix of the output wrt the input.\"\"\"\n",
    "\n",
    "        jacobian_matrix = torch.zeros(input_coords.shape[0], 2, 2)\n",
    "        for i in range(2):\n",
    "            jacobian_matrix[:, i, :] = self.gradient(input_coords, output[:, i])\n",
    "            if add_identity:\n",
    "                jacobian_matrix[:, i, i] += torch.ones_like(jacobian_matrix[:, i, i])\n",
    "        return jacobian_matrix      \n",
    "\n",
    "    def computeOgdenLoss(self, input_coords, output, batch_size=None, alpha_l=1, alpha_a=1, alpha_v=1):\n",
    "        \"\"\"Compute the Ogden regularization loss.\"\"\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        grad_u = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "        grad_y = self.computeJacobianMatrix(input_coords, output, add_identity=True)  # This is slow, faster to infer from grad_u\n",
    "\n",
    "        length_loss = torch.linalg.norm(grad_u, dim=(1, 2))\n",
    "        length_loss = torch.pow(length_loss, 2)\n",
    "        length_loss = torch.sum(length_loss)\n",
    "        length_loss = 0.5 * alpha_l * length_loss\n",
    "\n",
    "        # Compute cofactor matrices for the area loss\n",
    "        cofactors = torch.zeros(batch_size, 3, 3)\n",
    "\n",
    "        # Compute elements of cofactor matrices one by one (Ugliest solution ever?)\n",
    "        cofactors[:, 0, 0] = torch.det(grad_y[:, 1:, 1:])\n",
    "        cofactors[:, 0, 1] = torch.det(grad_y[:, 1:, 0::2])\n",
    "        cofactors[:, 0, 2] = torch.det(grad_y[:, 1:, :2])\n",
    "        cofactors[:, 1, 0] = torch.det(grad_y[:, 0::2, 1:])\n",
    "        cofactors[:, 1, 1] = torch.det(grad_y[:, 0::2, 0::2])\n",
    "        cofactors[:, 1, 2] = torch.det(grad_y[:, 0::2, :2])\n",
    "        cofactors[:, 2, 0] = torch.det(grad_y[:, :2, 1:])\n",
    "        cofactors[:, 2, 1] = torch.det(grad_y[:, :2, 0::2])\n",
    "        cofactors[:, 2, 2] = torch.det(grad_y[:, :2, :2])\n",
    "\n",
    "        # Compute area loss\n",
    "        area_loss = torch.linalg.norm(cofactors, dim=(1, 2))\n",
    "        area_loss = torch.pow(area_loss, 2)\n",
    "        area_loss = torch.sum(area_loss)\n",
    "        area_loss = alpha_a * area_loss\n",
    "\n",
    "        # Compute volume loss\n",
    "        volume_loss = torch.det(grad_y)\n",
    "        volume_loss = torch.abs(volume_loss)  # To prevent taking log of negative number\n",
    "        volume_loss = torch.pow(volume_loss, 2) - torch.log(volume_loss)\n",
    "        volume_loss = torch.sum(volume_loss)\n",
    "        volume_loss = alpha_v * volume_loss\n",
    "\n",
    "        # Compute total loss\n",
    "        loss = length_loss + area_loss + volume_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def computeQuadraticElasticLoss(self, input_coords, output, batch_size=None, nu=1, mu=1):\n",
    "        \"\"\"Compute the quadratic elastic regularization loss.\"\"\"\n",
    "\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        jacobian_matrix = self.computeJacobianMatrix(input_coords, output, add_identity=False)\n",
    "        jacobian_matrix_transpose = torch.transpose(jacobian_matrix, 1, 2)\n",
    "\n",
    "        E = jacobian_matrix + jacobian_matrix_transpose + torch.matmul(jacobian_matrix_transpose, jacobian_matrix)\n",
    "        E = 0.5 * E\n",
    "\n",
    "        loss = nu * torch.sum(torch.pow(self.computeTrace(E), 2))\n",
    "        loss += mu * self.computeTraceSum(torch.matmul(E, E))\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def computeTrace(self, tensor, n=3):\n",
    "        \"\"\"Compute the traces of an array of nxn matrices.\"\"\"\n",
    "\n",
    "        return torch.sum(torch.mul(tensor, torch.eye(n)), (1, 2))\n",
    "\n",
    "    def computeTraceSum(self, tensor, n=3):\n",
    "        \"\"\"Compute the sum of the traces of an array of nxn matrices.\"\"\"\n",
    "\n",
    "        return torch.sum(torch.mul(tensor, torch.eye(n)))\n",
    "\n",
    "    def cuda(self):\n",
    "        \"\"\"Move the model to the GPU.\"\"\"\n",
    "\n",
    "        # Standard variables\n",
    "        super().cuda()\n",
    "\n",
    "        # Variables specific to this class\n",
    "        self.moving_image.cuda()\n",
    "        self.fixed_image.cuda()\n",
    "        \n",
    "    def getBendingForZ(self, size=(28, 28), dimension=0, z=0.0):\n",
    "        output_size = np.prod(size)\n",
    "        coordinate_slice = self.makeCoordinateSlice(size, dimension, z).requires_grad_(True)\n",
    "        output = self.network(coordinate_slice)   \n",
    "        jacobian_matrix = self.computeJacobianMatrix(coordinate_slice, output, add_identity=False)\n",
    "\n",
    "        dx_xyz = torch.zeros(coordinate_slice.shape[0], 3, 3)\n",
    "        dy_xyz = torch.zeros(coordinate_slice.shape[0], 3, 3)\n",
    "        dz_xyz = torch.zeros(coordinate_slice.shape[0], 3, 3)\n",
    "        for i in range(3):\n",
    "            dx_xyz[:, i, :] = self.gradient(coordinate_slice, jacobian_matrix[:, i, 0])\n",
    "            dy_xyz[:, i, :] = self.gradient(coordinate_slice, jacobian_matrix[:, i, 1])\n",
    "            dz_xyz[:, i, :] = self.gradient(coordinate_slice, jacobian_matrix[:, i, 2])\n",
    "\n",
    "        dx_xyz = torch.square(dx_xyz)\n",
    "        dy_xyz = torch.square(dy_xyz)\n",
    "        dz_xyz = torch.square(dz_xyz)\n",
    "\n",
    "        bending = dx_xyz[:, :, 0] + dy_xyz[:, :, 1] + dz_xyz[:, :, 2]\n",
    "        bending += 2 * dx_xyz[:, :, 1] + 2 * dx_xyz[:, :, 2] + dy_xyz[:, :, 2]\n",
    "\n",
    "        return bending\n",
    "               \n",
    "    def getJacobianForZ(self, size=(28, 28), dimension=0, z=0.0):\n",
    "        \"\"\"Get the Jacobian Matrix and return its determinant.\"\"\"\n",
    "\n",
    "        output_size = np.prod(size)\n",
    "        coordinate_slice = self.makeCoordinateSlice(size, dimension, z).requires_grad_(True)\n",
    "        output = self.network(coordinate_slice)\n",
    "        jacobian_matrix = self.computeJacobianMatrix(coordinate_slice, output)\n",
    "        return torch.det(jacobian_matrix), output\n",
    "        \n",
    "        \n",
    "    def getJacobian(self, size=(28, 28), dimension=0):\n",
    "        \"\"\"Get the Jacobian Matrix and return its determinant.\"\"\"\n",
    "\n",
    "        jacobian_matrix = self.getJacobianMatrix(size, dimension)\n",
    "        determinant = torch.det(jacobian_matrix)\n",
    "        return determinant\n",
    "\n",
    "    def getJacobianMatrix(self, size=(28, 28), dimension=0):\n",
    "        \"\"\"Compute the jacobian matrix at points on a grid of size: self.jacobian_size.\n",
    "\n",
    "        computeJacobianMatrix is used during training when input and output are already availible.\n",
    "        getJacobianMatrix is used outside of training (e.g. for post-training visulaization).\n",
    "        \"\"\"\n",
    "\n",
    "        output_size = np.prod(size)\n",
    "\n",
    "        coordinate_slice = self.makeCoordinateSlice(size, dimension).requires_grad_(True)\n",
    "        \n",
    "        print(coordinate_slice)\n",
    "        time_vector = torch.zeros(output_size, 1)\n",
    "        if self.gpu:\n",
    "            time_vector = time_vector.cuda()\n",
    "\n",
    "        # output = self.network(torch.cat((coordinate_slice, time_vector), 1))\n",
    "        output = self.network(coordinate_slice)\n",
    "\n",
    "        output = output / self.velocity_steps\n",
    "\n",
    "        # Shift coordinates by 1/n * v\n",
    "        coord_temp = torch.add(output, coordinate_slice)\n",
    "\n",
    "        # Velocity field integration\n",
    "        for t in range(self.velocity_steps - 1):\n",
    "            time_vector = ((t + 1) / self.velocity_steps) * torch.ones(output_size, 1)\n",
    "            if self.gpu:\n",
    "                time_vector = time_vector.cuda()\n",
    "\n",
    "            output = self.network(torch.cat((coord_temp, time_vector), 1))\n",
    "\n",
    "            output = output / self.velocity_steps\n",
    "\n",
    "            # Shift coordinates by 1/n * v\n",
    "            coord_temp = torch.add(output, coord_temp)\n",
    "\n",
    "        output = torch.subtract(coord_temp, coordinate_slice)\n",
    "\n",
    "        jacobian_matrix = self.computeJacobianMatrix(coordinate_slice, output)\n",
    "        return jacobian_matrix\n",
    "\n",
    "    def getJacobianMatrixHist(self, size=(28, 28), dimension=0, batchsize=5000):\n",
    "        \"\"\"Compute the jacobian matrix at points on a grid of size: self.jacobian_size.\n",
    "\n",
    "        computeJacobianMatrix is used during training when input and output are already availible.\n",
    "        getJacobianMatrix is used outside of training (e.g. for post-training visulaization).\n",
    "        \"\"\"\n",
    "\n",
    "        output_size = np.prod(size)\n",
    "\n",
    "        coordinate_slice = torch.rand(batchsize, 3).requires_grad_(True) * 2 - 1\n",
    "        coordinate_slice = coordinate_slice.cuda()\n",
    "\n",
    "        time_vector = torch.zeros(batchsize, 1)\n",
    "        if self.gpu:\n",
    "            time_vector = time_vector.cuda()\n",
    "\n",
    "        output = self.network(torch.cat((coordinate_slice, time_vector), 1))\n",
    "\n",
    "        output = output / self.velocity_steps\n",
    "\n",
    "        # Shift coordinates by 1/n * v\n",
    "        coord_temp = torch.add(output, coordinate_slice)\n",
    "\n",
    "        # Velocity field integration\n",
    "        for t in range(self.velocity_steps - 1):\n",
    "            time_vector = ((t + 1) / self.velocity_steps) * torch.ones(output_size, 1)\n",
    "            if self.gpu:\n",
    "                time_vector = time_vector.cuda()\n",
    "\n",
    "            output = self.network(torch.cat((coord_temp, time_vector), 1))\n",
    "\n",
    "            output = output / self.velocity_steps\n",
    "\n",
    "            # Shift coordinates by 1/n * v\n",
    "            coord_temp = torch.add(output, coord_temp)\n",
    "\n",
    "        output = torch.subtract(coord_temp, coordinate_slice)\n",
    "\n",
    "        jacobian_matrix = self.computeJacobianMatrix(coordinate_slice, output)\n",
    "        determinant = torch.det(jacobian_matrix).detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.hist(determinant)\n",
    "        plt.show()\n",
    "        return determinant\n",
    "    \n",
    "    def interpolate(self, input_array, coordinates):\n",
    "        return faster_bilinear_interpolation(input_array, coordinates[:, 0], coordinates[:, 1])\n",
    "    \n",
    "    def setDefaultArguments(self):\n",
    "        \"\"\"Set default arguments.\"\"\"\n",
    "\n",
    "        # Inherit default arguments from standard learning model\n",
    "        super().setDefaultArguments()\n",
    "\n",
    "        # Define the value of arguments\n",
    "        self.args['mask'] = None\n",
    "        self.args['mask_2'] = None\n",
    "\n",
    "        self.args['method'] = 1\n",
    "\n",
    "        self.args['lr'] = 0.0001\n",
    "        self.args['batch_size'] = 5000\n",
    "        self.args['layers'] = [4, 64, 64, 64, 3] # [3, 64, 64, 64, 3]\n",
    "        self.args['gif_name'] = 'ImplicitRegistrator.gif'\n",
    "        self.args['velocity_steps'] = 1\n",
    "\n",
    "        # Define argument defaults specific to this class\n",
    "        self.args['output_regularization'] = False\n",
    "        self.args['alpha_output'] = 0.2\n",
    "        self.args['reg_norm_output'] = 1\n",
    "\n",
    "        self.args['jacobian_regularization'] = False\n",
    "        self.args['alpha_jacobian'] = 0.085\n",
    "        self.args['reg_norm_jacobian'] = 1\n",
    "\n",
    "        self.args['diffusion_regularization'] = False\n",
    "        self.args['alpha_diffusion'] = 0.01\n",
    "\n",
    "        self.args['elastic_regularization'] = False\n",
    "        self.args['alpha_elastic'] = 0.01\n",
    "\n",
    "        self.args['quadratic_regularization'] = False\n",
    "        self.args['alpha_quadratic'] = 0.01\n",
    "\n",
    "        self.args['ogden_regularization'] = False\n",
    "        self.args['alpha_ogden'] = 0.01\n",
    "\n",
    "        self.args['hyper_regularization'] = False\n",
    "        self.args['alpha_hyper'] = 0.01\n",
    "\n",
    "        self.args['time_regularization'] = False\n",
    "        self.args['alpha_time'] = 0.01\n",
    "\n",
    "        self.args['bending_regularization'] = False\n",
    "        self.args['alpha_bending'] = 0.05\n",
    "\n",
    "        self.args['image_shape'] = (200, 200)\n",
    "\n",
    "        self.args['inbetween_images'] = None\n",
    "        self.args['inbetween_alpha'] = 0.1\n",
    "        \n",
    "    def train(self, epochs=None, red_blue=True):\n",
    "        \"\"\"Train the network.\n",
    "\n",
    "        This function inherits the function from the super-class, but with different default arguments.\n",
    "        \"\"\"\n",
    "\n",
    "        super().train(epochs, red_blue)\n",
    "\n",
    "    def trainingIteration(self, epoch):\n",
    "        \"\"\"Perform one iteration of training.\"\"\"\n",
    "\n",
    "        # Reset the gradient\n",
    "        self.network.train()\n",
    "\n",
    "        loss = 0\n",
    "        \n",
    "        indices = torch.randperm(self.possible_coordinate_tensor.shape[0], device='cuda')[:int(self.batch_size/25)]\n",
    "        coordinate_tensor = self.possible_coordinate_tensor[indices, :]\n",
    "        coordinate_tensor = torch.repeat_interleave(coordinate_tensor, torch.tensor(np.ones(int(self.batch_size/25))*25).int().cuda(), dim=0)\n",
    "                \n",
    "        coordinate_tensor = coordinate_tensor + self.coordinate_tensor_loc\n",
    "        # print(coordinate_tensor)\n",
    "        # print(coordinate_tensor_loc.shape)        \n",
    "        \n",
    "        # coordinate_tensor = coordinate_tensor[mask.flatten() > 0, :]        \n",
    "        coordinate_tensor = coordinate_tensor.requires_grad_(True) \n",
    "\n",
    "#         if self.gpu:\n",
    "#             coordinate_tensor = coordinate_tensor.cuda()\n",
    "\n",
    "        output = self.network(coordinate_tensor) + self.offset\n",
    "        coord_temp = torch.add(output, coordinate_tensor)\n",
    "        output = coord_temp\n",
    "        \n",
    "        transformed_image = self.transformNoAdd(coord_temp)\n",
    "        fixed_image = self.interpolate(self.fixed_image, coordinate_tensor)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss += self.criterion(transformed_image, fixed_image)\n",
    "\n",
    "        # Store the value of the data loss\n",
    "        if self.verbose:\n",
    "            self.data_loss_list[epoch] = loss.detach().cpu().numpy()\n",
    "\n",
    "        # Relativation of output\n",
    "        output_rel = torch.subtract(output, coordinate_tensor)\n",
    "\n",
    "        # Regularization\n",
    "        if self.output_regularization:\n",
    "            loss += self.alpha_output * torch.linalg.norm(output_rel, self.reg_norm_output) / (2 * self.batch_size)\n",
    "        if self.jacobian_regularization: #  and epoch > self.epochs//2:\n",
    "            loss += self.alpha_jacobian * self.computeJacobianLoss(coordinate_tensor, output_rel)\n",
    "        if self.diffusion_regularization:\n",
    "            loss += self.alpha_diffusion * self.computeDiffusionLoss(coordinate_tensor, output_rel)\n",
    "        if self.elastic_regularization:\n",
    "            loss += self.alpha_elastic * self.computeElasticLoss(coordinate_tensor, output_rel)\n",
    "        if self.quadratic_regularization:\n",
    "            loss += self.alpha_quadratic * self.computeQuadraticElasticLoss(coordinate_tensor, output_rel)\n",
    "        if self.ogden_regularization:\n",
    "            loss += self.alpha_ogden * self.computeOgdenLoss(coordinate_tensor, output_rel)\n",
    "        if self.hyper_regularization:\n",
    "            loss += self.alpha_hyper * self.computeHyperElasticLoss(coordinate_tensor, output_rel)\n",
    "        if self.bending_regularization:\n",
    "            loss += self.alpha_bending * self.computeBendingEnergy(coordinate_tensor, output_rel)            \n",
    "\n",
    "        # Perform the backpropagation and update the parameters accordingly\n",
    "        # self.optimizer.zero_grad()\n",
    "        for param in self.network.parameters():\n",
    "            param.grad = None        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Regularization scheduler\n",
    "        #         if epoch == self.epochs // 3:\n",
    "        #             self.alpha_hyper *= 0.1\n",
    "        # self.scheduler.step()\n",
    "\n",
    "        # Store the value of the total loss\n",
    "        if self.verbose:\n",
    "            self.loss_list[epoch] = loss.detach().cpu().numpy()\n",
    "        \n",
    "#         # Print Logs\n",
    "#         if (epoch % self.log_interval == 0 or epoch == self.epochs - 1):\n",
    "#             # self.saveNetwork('network_' + str(epoch) + '.pt')\n",
    "#             if self.verbose:\n",
    "#                 with torch.no_grad():\n",
    "#                     output = self.network(self.coordinate_slice)\n",
    "#                     transformed_image = self.transform(output, self.coordinate_slice)\n",
    "#                     self.printLogs(epoch, loss, transformed_image, output, coordinate_tensor.detach().cpu().numpy())\n",
    "\n",
    "    def transform(self, transformation, coordinate_tensor=None, moving_image=None, reshape=False):\n",
    "        \"\"\"Transform moving image given a transformation.\"\"\"\n",
    "\n",
    "        # If no specific coordinate tensor is given use the standard one of 28x28\n",
    "        if coordinate_tensor is None:\n",
    "            coordinate_tensor = self.coordinate_tensor\n",
    "\n",
    "        # If no moving image is given use the standard one\n",
    "        if moving_image is None:\n",
    "            moving_image = self.moving_image\n",
    "\n",
    "        # From relative to absolute\n",
    "        transformation = torch.add(transformation, coordinate_tensor)\n",
    "        return self.interpolate(moving_image, transformation)\n",
    "\n",
    "    def transformNoAdd(self, transformation, moving_image=None, reshape=False):\n",
    "        \"\"\"Transform moving image given a transformation.\"\"\"\n",
    "\n",
    "        # If no moving image is given use the standard one\n",
    "        if moving_image is None:\n",
    "            moving_image = self.moving_image\n",
    "        # print('GET MOVING')\n",
    "        return self.interpolate(moving_image, transformation)\n",
    "    \n",
    "    def plotDeterminant(self, dims=(100, 100), clip=False, epsilon=0.00001, colormap='seismic', dimension=0):\n",
    "        \"\"\"Plots the determinant of the jacobian matrix of the transform.\"\"\"\n",
    "\n",
    "        jacobian = self.getJacobian(dims, dimension)\n",
    "\n",
    "        # Reshape determinant\n",
    "        jacobian = jacobian.detach().numpy().reshape(dims)\n",
    "\n",
    "        print('Percentage negative {}'.format(np.sum(jacobian < 0)/np.prod(jacobian.shape)))\n",
    "        # Make figure\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        # Clip values\n",
    "        if clip:\n",
    "            jacobian[jacobian < -1 - epsilon] = - 1 - epsilon\n",
    "            jacobian[jacobian > 1 + epsilon] = 1 + epsilon\n",
    "            plt.imshow(jacobian, cmap=colormap, norm=plt.Normalize(vmin=-1 - epsilon, vmax=1 + epsilon))\n",
    "        else:\n",
    "            maxval = np.max(np.abs(jacobian))\n",
    "            plt.imshow(jacobian, cmap=colormap, norm=plt.Normalize(vmin=-maxval, vmax=maxval))\n",
    "\n",
    "        # Plotting\n",
    "        plt.title(\"Jacobian\", fontsize=20)\n",
    "        plt.yticks([]), plt.xticks([])\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "    def fillPixel(self, dims, dimension = 1):\n",
    "        coordinate_slice = self.makeCoordinateSlice(dims, dimension=dimension).requires_grad_(True)\n",
    "        output = self.network(coordinate_slice)\n",
    "        output = torch.cat((coordinate_slice, output), 1)\n",
    "        print(output.shape)\n",
    "        return output\n",
    "        \n",
    "    def plotDifferenceImage(self, output_shape=(500, 500), dimension=0, slice_pos=0, mask_overlay=False):\n",
    "        \"\"\"Plot an image of the difference between fixed image and transformed moving image.\"\"\"\n",
    "\n",
    "        moving_image = self(output_shape=output_shape, dimension=dimension, slice_pos=slice_pos)\n",
    "        fixed_image = self.interpolate(self.fixed_image, self.makeCoordinateSlice(output_shape, dimension, slice_pos))\n",
    "        fixed_image = fixed_image.detach().cpu().view(self.output_shape)\n",
    "\n",
    "        difference_image = np.abs(moving_image - fixed_image)\n",
    "\n",
    "        if mask_overlay:\n",
    "            difference_image_rgb = np.zeros(output_shape[0], output_shape[1], 3)\n",
    "            difference_image_rgb[:, :, 0] = difference_image\n",
    "\n",
    "            # Transformed version of mask         FIX THIS\n",
    "            mask = np.random.rand(*output_shape)\n",
    "            difference_image[:, :, 2] = mask\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "\n",
    "        # Imshow  rgb/grayscale   depending on   mask_overlay\n",
    "        if mask_overlay:\n",
    "            plt.imshow(difference_image, cmap='gray', norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        else:\n",
    "            plt.imshow(difference_image, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "\n",
    "        plt.title('Difference image', fontsize=20)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    def printLogs(self, epoch, loss, transformed_image, output, locations):\n",
    "        \"\"\"Print the progress of the training.\"\"\"\n",
    "\n",
    "        # Make figure and axis\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        # Print Loss\n",
    "        print(\"-\" * 10 + \"  epoch: \" + str(epoch) + \"  \" + \"-\" * 10)\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        print(\"Loss: \" + str(loss) + '   PSNR: ' + str(-10 * np.log10(loss)))\n",
    "\n",
    "        # Reshape transformed image\n",
    "        transformed_image_plot = torch.FloatTensor(transformed_image.cpu().detach().numpy().reshape(*self.image_shape))\n",
    "\n",
    "        # Compute difference image\n",
    "        difference_image = torch.abs(torch.subtract(transformed_image_plot, self.fixed_image_tensor_masked))\n",
    "\n",
    "        # Plot interpolated, fixed and difference image\n",
    "        transformed_result = transformed_image.detach().cpu().numpy().reshape(*self.image_shape)\n",
    "        fixed_ref = self.fixed_image_tensor_masked.numpy()\n",
    "        \n",
    "        ax1.imshow(transformed_result, cmap='gray') # , norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        ax1.set_title(\"Deformed Image\", fontsize=20)\n",
    "        # ax1.set_yticks([]), ax1.set_xticks([])\n",
    "        \n",
    "        ax2.imshow(fixed_ref, cmap='gray') # , norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        ax2.set_title(\"Target\", fontsize=20)\n",
    "        # ax2.set_yticks([]), ax2.set_xticks([])\n",
    "\n",
    "        ax3.imshow(difference_image.detach().cpu().numpy().reshape(*self.image_shape), cmap='seismic') # , norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        ax3.set_title(\"Difference\", fontsize=20)\n",
    "        # ax3.set_yticks([]), ax3.set_xticks([])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.scatter(locations[:, 0], locations[:, 1])\n",
    "        \n",
    "        output_normed = np.linalg.norm(output.detach().cpu().numpy(), axis=1)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(output_normed.reshape(*self.image_shape))\n",
    "        plt.show()    \n",
    "        \n",
    "        plt.figure(figsize=(20,20))       \n",
    "        \n",
    "        comp_registered = compare_images(fixed_ref, transformed_result, method='checkerboard', n_tiles=(4, 4))\n",
    "        plt.imshow(comp_registered, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(20,20))       \n",
    "        \n",
    "        comp_registered = compare_images(fixed_ref, transformed_result, method='diff')\n",
    "        plt.imshow(comp_registered, cmap='gray')\n",
    "        plt.show()\n",
    "                \n",
    "        plt.figure(figsize=(20,20))       \n",
    "        \n",
    "        alpha = 0.6\n",
    "        target_image_rgb = np.transpose(np.stack((fixed_ref, fixed_ref, fixed_ref)) ,axes=[1,2,0]) * 255\n",
    "        target_image_rgb = target_image_rgb.astype(np.uint8)\n",
    "        aligned_images_rgb = target_image_rgb\n",
    "        aligned_images_rgb[:,:,1] = alpha*transformed_result*255 + (1-alpha)*aligned_images_rgb[:,:,1]\n",
    "        aligned_images_rgb = aligned_images_rgb.astype(np.uint8)\n",
    "        # plt.imshow(aligned_images_rgb)        \n",
    "        plt.imshow(target_image_rgb)\n",
    "        \n",
    "        # plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890ca57",
   "metadata": {},
   "source": [
    "Bilinear interpolation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485f7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_bilinear_interpolation(input_array, x_indices, y_indices):\n",
    "    \n",
    "    x_indices = (x_indices + 1) * (input_array.shape[0]-1) * 0.5\n",
    "    y_indices = (y_indices + 1) * (input_array.shape[1]-1) * 0.5\n",
    "    \n",
    "    x0 = torch.floor(x_indices.detach()).to(torch.long)\n",
    "    y0 = torch.floor(y_indices.detach()).to(torch.long)\n",
    "    x1 = x0 + 1\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = torch.clamp(x0, 0, input_array.shape[0] - 1)\n",
    "    y0 = torch.clamp(y0, 0, input_array.shape[1] - 1)\n",
    "    x1 = torch.clamp(x1, 0, input_array.shape[0] - 1)\n",
    "    y1 = torch.clamp(y1, 0, input_array.shape[1] - 1)\n",
    "\n",
    "    x = x_indices - x0\n",
    "    y = y_indices - y0\n",
    "\n",
    "    output = input_array[x0, y0] * (1 - x) * (1 - y) + input_array[x1, y0] * x * (1 - y) + input_array[x0, y1] * (1 - x) * y + input_array[x1, y1] * x * y\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28991ffc",
   "metadata": {},
   "source": [
    "Load CSV, load images, perform registration, update and save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e743b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeSantiB\\AppData\\Local\\Temp\\ipykernel_18872\\2379991696.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csvfile.he_x[row_idxs[0]] = ihc_x_um\n",
      "C:\\Users\\DeSantiB\\AppData\\Local\\Temp\\ipykernel_18872\\2379991696.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  csvfile.he_y[row_idxs[0]] = ihc_y_um\n",
      "  5%|                                                                       | 4789/100000 [00:11<04:06, 386.58it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2 \n",
    "import skimage.transform\n",
    "import scipy.ndimage as scnd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csvpath = r'D:\\ACROBAT Data\\acrobat_validation_points_public_1_of_1.csv'\n",
    "datafolder = r'D:\\ACROBAT Data\\acrobat_validation_pyramid_1_of_1'\n",
    "output_csvpath = r'D:\\ACROBAT Data\\output\\csv_output.csv'\n",
    "output_image_path = r'D:\\ACROBAT Data\\output\\images'\n",
    "\n",
    "shutil.copy(csvpath,output_csvpath)\n",
    "csvfile = pd.read_csv(csvpath)\n",
    "\n",
    "train_val_str = 'test' # train, val or test\n",
    "pyr = 0\n",
    "original_scale = 10 # the scale of the loaded images\n",
    "anon_ids = csvfile.anon_id\n",
    "\n",
    "for idq in np.unique(anon_ids):\n",
    "    row_idxs = np.where(anon_ids == idq)\n",
    "    target_stain = 'HE'\n",
    "    source_stain = csvfile.ihc_antibody[row_idxs[0][0]]\n",
    "\n",
    "    res_he_10X = csvfile.mpp_he_10X[row_idxs[0][0]]\n",
    "    res_ihc_10X = csvfile.mpp_ihc_10X[row_idxs[0][0]]\n",
    "\n",
    "    pp_scale = 1 # desired scale for preprocessing\n",
    "    pp_res_he = res_he_10X*(10/pp_scale)\n",
    "    pp_res_ihc = res_ihc_10X*(10/pp_scale)\n",
    "\n",
    "    ihc_x_um = csvfile.ihc_x[row_idxs[0]]\n",
    "    ihc_y_um = csvfile.ihc_y[row_idxs[0]]\n",
    "    ihc_x = ihc_x_um/res_ihc_10X\n",
    "    ihc_y = ihc_y_um/res_ihc_10X\n",
    "\n",
    "    pp_ihc_x = ihc_x_um/pp_res_ihc\n",
    "    pp_ihc_y = ihc_y_um/pp_res_ihc\n",
    "    pp_ihc_points = np.column_stack((pp_ihc_x,pp_ihc_y))\n",
    "\n",
    "    csvfile.he_x[row_idxs[0]] = ihc_x_um\n",
    "    csvfile.he_y[row_idxs[0]] = ihc_y_um\n",
    "\n",
    "    target_image = load_acrobat_image(datafolder, str(idq), target_stain, pyr, train_val_str)\n",
    "    source_image = load_acrobat_image(datafolder, str(idq), source_stain, pyr, train_val_str)\n",
    "\n",
    "    # Image rescaling\n",
    "    h,w,s = target_image.shape\n",
    "    h //= int(original_scale/pp_scale)\n",
    "    w //= int(original_scale/pp_scale)\n",
    "    pp_target_image = cv2.resize(target_image, dsize=(w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    h,w,s = source_image.shape\n",
    "    h //= int(original_scale/pp_scale)\n",
    "    w //= int(original_scale/pp_scale)\n",
    "    pp_source_image = cv2.resize(source_image, dsize=(w, h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Colorspace conversion\n",
    "    pp_target_lab = cv2.cvtColor(pp_target_image,cv2.COLOR_RGB2Lab)\n",
    "    target_show_keypoints,target_kp,target_des,target_tissue_mask,processed_target_channel = sift_he(pp_target_lab, pp_res_he)\n",
    "    target_tissue_mask = target_tissue_mask.astype(np.uint8)\n",
    "\n",
    "    pp_source_hsv = cv2.cvtColor(pp_source_image,cv2.COLOR_RGB2HSV)\n",
    "    source_show_keypoints,source_kp,source_des,source_tissue_mask,processed_source_channel = sift_ihc(pp_source_hsv, pp_res_ihc)\n",
    "\n",
    "    # SIFT matching\n",
    "    good_source_kp, good_target_kp,show_matching_keypoints = matching_keypoints(pp_source_image,pp_target_image,source_des,target_des,source_kp,target_kp,lowe_ratio=0.95)\n",
    "    \n",
    "    # RANSAC\n",
    "    best_M,best_ninliers,best_dice,show_best_matching_keypoints = dransac(good_source_kp, good_target_kp, source_tissue_mask, target_tissue_mask, processed_source_channel, processed_target_channel, pp_source_image, pp_target_image,epochs = 100000)\n",
    "\n",
    "    # Apply rigid transformation to the IHC image\n",
    "    pp_cols = pp_target_image.shape[1]\n",
    "    pp_rows = pp_target_image.shape[0]\n",
    "    processed_source_channel_rigid = cv2.warpAffine(processed_source_channel, best_M, (pp_cols,pp_rows))\n",
    "\n",
    "    # Apply rigid transformation to the IHC points and update the CSV file\n",
    "    pp_ihc_points_rigid = cv2.transform(np.array([pp_ihc_points]),best_M)\n",
    "    ihc_points_rigid_um = pp_ihc_points_rigid*pp_res_ihc\n",
    "    ihc_x_rigid_um = ihc_points_rigid_um[0][:,0]\n",
    "    ihc_y_rigid_um = ihc_points_rigid_um[0][:,1]\n",
    "    csvfile.he_x[row_idxs[0]] = ihc_x_rigid_um\n",
    "    csvfile.he_y[row_idxs[0]] = ihc_y_rigid_um\n",
    "    csvfile.to_csv(output_csvpath, index=False)\n",
    "\n",
    "    # Debug figures for rigid transformation\n",
    "    aligned_images_rgb = show_aligned_images(processed_source_channel_rigid, processed_target_channel,alpha=0.6)\n",
    "\n",
    "    fig = plt.figure(figsize = (20,20))\n",
    "    plt.imshow(show_best_matching_keypoints)\n",
    "    plt.axis('off')\n",
    "\n",
    "    fig = plt.figure(figsize = (20,20))\n",
    "    plt.imshow(aligned_images_rgb)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Image preprocessing before INR\n",
    "    inr_target_image = processed_target_channel/255.0\n",
    "    inr_target_image = torch.FloatTensor(inr_target_image)\n",
    "\n",
    "    inr_source_image = processed_source_channel_rigid/255.0\n",
    "    inr_source_image = torch.FloatTensor(inr_source_image)\n",
    "\n",
    "    # Dilate tissue mask of HE (helps the INR)\n",
    "    inr_target_mask = np.clip(target_tissue_mask, 0, 1)\n",
    "    inr_target_mask = scnd.binary_dilation(inr_target_mask, np.ones((51, 51)))\n",
    "\n",
    "    # If needed, save the input images before the INR\n",
    "    # np.save(output_image_path + os.path.sep + str(idq) + '_HE_1x', processed_target_channel)\n",
    "    # np.save(output_image_path + os.path.sep + str(idq) + '_' + source_stain + '_rigid_1x', processed_source_channel_rigid)\n",
    "    # np.save(output_image_path + os.path.sep + str(idq) + '_HE_mask_1x', target_tissue_mask)\n",
    "\n",
    "\n",
    "    # INR parameters\n",
    "    kwargs = {}\n",
    "    kwargs['layers'] = [2, 256, 256, 256, 2] \n",
    "    kwargs['verbose'] = True \n",
    "    kwargs['optimizer'] = 'adam' \n",
    "    kwargs['lr'] = 0.00001\n",
    "    kwargs['batch_size'] = 250 * 25  \n",
    "    kwargs['hyper_regularization'] = False \n",
    "    kwargs['time_regularization'] = False\n",
    "    kwargs['elastic_regularization'] = False \n",
    "    kwargs['quadratic_regularization'] = False\n",
    "    kwargs['jacobian_regularization'] = False  \n",
    "    kwargs['bending_regularization'] = False\n",
    "    kwargs['epochs'] = 25000\n",
    "    kwargs['log_interval'] = kwargs['epochs']//4\n",
    "    kwargs['omega'] = 16 \n",
    "    kwargs['alpha_hyper'] = 0.25\n",
    "    kwargs['alpha_quadratic'] = 0.1\n",
    "    kwargs['alpha_jacobian'] = 0.1\n",
    "    kwargs['alpha_elastic'] = 0.5\n",
    "    kwargs['alpha_bending'] = 10\n",
    "    kwargs['velocity_steps'] = 1\n",
    "    kwargs['save_folder'] = r'D:\\ACROBAT Data\\csv_rigid_val\\output_inr\\{}'.format(str(idq))\n",
    "    kwargs['mask'] = inr_target_mask\n",
    "    kwargs['loss_function'] = 'ncc'\n",
    "    kwargs['offset'] = [0, 0]\n",
    "    kwargs['gabor_scale'] = 32\n",
    "\n",
    "    ImpReg = ImplicitRegistrator(inr_source_image, inr_target_image, **kwargs)\n",
    "    ImpReg.train()\n",
    "    \n",
    "    # Apply INR transformation to the IHC moving image (using batches of coordinates to avoid out of GPU memory)\n",
    "    output_shape = (inr_target_image.shape[0],inr_target_image.shape[1])\n",
    "    grid_tensor = ImpReg.makeCoordinateSlice(ImpReg.image_shape, 1, 0)\n",
    "    inr_source_image_reg = np.zeros(grid_tensor.shape[0])\n",
    "    \n",
    "    forward_batch_size = 10000;\n",
    "    index = 0\n",
    "    for grid_batch in torch.split(grid_tensor, forward_batch_size):\n",
    "        inr_source_image_reg[index:index + forward_batch_size] = ImpReg(grid_batch)\n",
    "        index = index + forward_batch_size\n",
    "    inr_source_image_reg = inr_source_image_reg.reshape(output_shape)\n",
    "\n",
    "    # Apply INR transformation to the IHC points\n",
    "    inr_res_ihc = pp_res_ihc\n",
    "    inr_ihc_x = pp_ihc_points_rigid[0][:,0]\n",
    "    inr_ihc_y = pp_ihc_points_rigid[0][:,1]\n",
    "    inr_ihc_points = np.column_stack((inr_ihc_x,inr_ihc_y))\n",
    "\n",
    "    # From absolute to relative here \n",
    "    inr_ihc_points_rel = inr_ihc_points.copy()\n",
    "    inr_ihc_points_rel[:,1] = (2 * inr_ihc_points[:,0]) / (inr_target_image.shape[1] - 1) - 1\n",
    "    inr_ihc_points_rel[:,0] = (2 * inr_ihc_points[:,1]) / (inr_target_image.shape[0] - 1) - 1\n",
    "\n",
    "    # Move points\n",
    "    inr_ihc_points_rel_tensor = torch.from_numpy(np.float32(inr_ihc_points_rel))\n",
    "    inr_ihc_points_rel_tensor = inr_ihc_points_rel_tensor.cuda()\n",
    "\n",
    "    output = ImpReg.network(inr_ihc_points_rel_tensor)\n",
    "\n",
    "    inr_ihc_points_rel_tensor_reg = torch.subtract(output, inr_ihc_points_rel_tensor)\n",
    "    inr_ihc_points_tensor_reg = inr_ihc_points_rel_tensor_reg.clone()\n",
    "\n",
    "    # and then back to absolute\n",
    "    inr_ihc_points_tensor_reg[:,0] = inr_target_image.shape[0]/2*(-inr_ihc_points_rel_tensor_reg[:,0] + 1)\n",
    "    inr_ihc_points_tensor_reg[:,1] = inr_target_image.shape[1]/2*(-inr_ihc_points_rel_tensor_reg[:,1] + 1)\n",
    "\n",
    "    inr_ihc_points_reg = inr_ihc_points_tensor_reg.cpu().detach().numpy()\n",
    "    inr_ihc_points_reg_x = inr_ihc_points_reg[:,1]\n",
    "    inr_ihc_points_reg_y = inr_ihc_points_reg[:,0]\n",
    "    inr_ihc_points_reg_x_um = inr_ihc_points_reg_x*inr_res_ihc\n",
    "    inr_ihc_points_reg_y_um = inr_ihc_points_reg_y*inr_res_ihc\n",
    "    \n",
    "    # INR transformation figures\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax = fig.add_subplot(2, 1, 1)\n",
    "    aligned_images_rgb = show_aligned_images(inr_source_image*255, inr_target_image*255,alpha=0.6)\n",
    "    ax.imshow(aligned_images_rgb)\n",
    "    ax.axis('off')\n",
    "    ax = fig.add_subplot(2, 1, 2)\n",
    "    aligned_images_rgb = show_aligned_images(inr_source_image_reg*255, inr_target_image*255,alpha=0.6)\n",
    "    ax.imshow(aligned_images_rgb)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Update the CSV file\n",
    "    csvfile.he_x[row_idxs[0]] = inr_ihc_points_reg_x_um\n",
    "    csvfile.he_y[row_idxs[0]] = inr_ihc_points_reg_y_um\n",
    "    csvfile.to_csv(output_csvpath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
